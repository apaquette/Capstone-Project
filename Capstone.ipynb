{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41af137f",
   "metadata": {},
   "source": [
    "# IBM Data Analyst Capstone Project\n",
    "by Alex Paquette\n",
    "\n",
    "This project is completed as part of IBM's Data Analyst Professional Certificate. It demonstrates my ability to go through the entire Data Analyst process, which is listed below:\n",
    "\n",
    "1. Data Collection\n",
    "2. Data Wrangling\n",
    "3. Exploratory Data Analysis\n",
    "4. Data Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b57c2d",
   "metadata": {},
   "source": [
    "Install required libraries using `pip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d456674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.13/site-packages (26.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.13/site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.13/site-packages (from pandas) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install pandas\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc29f1f2",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "8652efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b0aea",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "There are a variety of methods that we can use to collect data. We can gather data via APIs, web scraping, and file reading (excel, csv, json, etc.). For this project, we will be using a .csv file provided by Coursera. It can be obtained from the following URL:\n",
    "\n",
    "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VYPrOu0Vs3I0hKLLjiPGrA/survey-data-with-duplicate.csv\n",
    "\n",
    "We will be using this dataset to go through the Data Analysis process, starting with data collection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0359e9fa",
   "metadata": {},
   "source": [
    "## About the Dataset\n",
    "\n",
    "Before we go any further, it's important to understand what attributes we're working with. This will help us during the Data Wrangling stage and will inform how we handle duplicates and missing values.\n",
    "\n",
    "The dataset in question are responses from the **Stack Overflow Developer Survey**.\n",
    "\n",
    "### Column Description for Survey Data\n",
    "| Column name | Question text |\n",
    "| --- | --- |\n",
    "| ResponseId | Randomized respondent ID number|\n",
    "| MainBranch | Which of the following options best describes you today?|\n",
    "| Age | What is your age?|\n",
    "| Employment | What is your current employment status? |\n",
    "| RemoteWork | How often do you work remotely? |\n",
    "| Check | Check Various verification or check questions related to survey consistency |\n",
    "| CodingActivities | What coding activities do you engage in? |\n",
    "| EdLevel | What is the highest level of formal education you have completed? |\n",
    "| LearnCode | How did you learn to code? |\n",
    "| LearnCodeOnline | Have you used online resources to learn coding? |\n",
    "| TechDoc | How do you use technical documentation? |\n",
    "| YearsCode | How many years have you been coding? |\n",
    "| DevType | What is your role or type of development you do? |\n",
    "| OrgSize | What is the size of the organization you work for? |\n",
    "| PurchaseInfluence | How much influence do you have on purchasing technology at your company? |\n",
    "| BuyNewTool | How does your company decide whether to buy new tools or technology? |\n",
    "| BuildvsBuy | Does your company prefer to build or buy software? |\n",
    "| TechEndorse | Do you endorse any specific technologies at your company? |\n",
    "| Country | In which country do you reside? |\n",
    "| Currency | Which currency do you use day-to-day? |\n",
    "| CompTotal | What is your current total compensation? |\n",
    "| LanguageHaveWorkedWith | Which programming languages have you worked with in the past year? |\n",
    "| LanguageWantToWorkWith | Which programming languages do you want to work with in the future? |\n",
    "| LanguageAdmired | Which programming languages do you admire most? |\n",
    "| DatabaseHaveWorkedWith | Which database technologies have you worked with in the past year? |\n",
    "| DatabaseWantToWorkWith | Which database technologies do you want to work with in the future? |\n",
    "| DatabaseAdmired | Which database technologies do you admire most? |\n",
    "| PlatformHaveWorkedWith | Which platforms have you worked with in the past year? |\n",
    "| PlatformWantToWorkWith | Which platforms do you want to work with in the future? |\n",
    "| PlatformAdmired | Which platforms do you admire most? |\n",
    "| WebframeHaveWorkedWith | Which web frameworks have you worked with in the past year? |\n",
    "| WebframeWantToWorkWith | Which web frameworks do you want to work with in the future? |\n",
    "| WebframeAdmired | Which web frameworks do you admire most? |\n",
    "| EmbeddedHaveWorkedWith | Which embedded systems have you worked with in the past year? |\n",
    "| EmbeddedWantToWorkWith | Which embedded systems do you want to work with in the future? |\n",
    "| EmbeddedAdmired | Which embedded systems do you admire most? |\n",
    "| MiscTechHaveWorkedWith | Which miscellaneous technologies have you worked with in the past year? |\n",
    "| MiscTechWantToWorkWith | Which miscellaneous technologies do you want to work with in the future? |\n",
    "| MiscTechAdmired | Which miscellaneous technologies do you admire most? |\n",
    "| SOVisitFreq | How frequently do you visit Stack Overflow? |\n",
    "| SOPartFreq | How often do you participate in Q&A on Stack Overflow? |\n",
    "| AISelect | How do you feel about artificial intelligence tools for development? |\n",
    "| AIBen | What benefits have you experienced from using AI tools? |\n",
    "| AIChallenges | What challenges have you faced while using AI tools? |\n",
    "| JobSat | How satisfied are you with your current job? |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357777f8",
   "metadata": {},
   "source": [
    "This is quite a comprehensive list of questions, and far too many for us to work with in the scope of this project. We will be selecting which attributes we want to keep for our anaysis and which we want to drop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11331a20",
   "metadata": {},
   "source": [
    "We will use the `pandas.read_csv()` method to read the provided CSV file and store it into a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "08e293e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/VYPrOu0Vs3I0hKLLjiPGrA/survey-data-with-duplicate.csv'\n",
    "df = pd.read_csv(file_path) #read csv into a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c8060",
   "metadata": {},
   "source": [
    "We can use the `head()` function to see the first five records of this dataset. This gives us confidence that the data was loaded properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "dca8eeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>MainBranch</th>\n",
       "      <th>Age</th>\n",
       "      <th>Employment</th>\n",
       "      <th>RemoteWork</th>\n",
       "      <th>Check</th>\n",
       "      <th>CodingActivities</th>\n",
       "      <th>EdLevel</th>\n",
       "      <th>LearnCode</th>\n",
       "      <th>LearnCodeOnline</th>\n",
       "      <th>...</th>\n",
       "      <th>JobSatPoints_6</th>\n",
       "      <th>JobSatPoints_7</th>\n",
       "      <th>JobSatPoints_8</th>\n",
       "      <th>JobSatPoints_9</th>\n",
       "      <th>JobSatPoints_10</th>\n",
       "      <th>JobSatPoints_11</th>\n",
       "      <th>SurveyLength</th>\n",
       "      <th>SurveyEase</th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "      <th>JobSat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>Under 18 years old</td>\n",
       "      <td>Employed, full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Hobby</td>\n",
       "      <td>Primary/elementary school</td>\n",
       "      <td>Books / Physical media</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>35-44 years old</td>\n",
       "      <td>Employed, full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Hobby;Contribute to open-source projects;Other...</td>\n",
       "      <td>Bachelor’s degree (B.A., B.S., B.Eng., etc.)</td>\n",
       "      <td>Books / Physical media;Colleague;On the job tr...</td>\n",
       "      <td>Technical documentation;Blogs;Books;Written Tu...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>45-54 years old</td>\n",
       "      <td>Employed, full-time</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Apples</td>\n",
       "      <td>Hobby;Contribute to open-source projects;Other...</td>\n",
       "      <td>Master’s degree (M.A., M.S., M.Eng., MBA, etc.)</td>\n",
       "      <td>Books / Physical media;Colleague;On the job tr...</td>\n",
       "      <td>Technical documentation;Blogs;Books;Written Tu...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Appropriate in length</td>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>I am learning to code</td>\n",
       "      <td>18-24 years old</td>\n",
       "      <td>Student, full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>Other online resources (e.g., videos, blogs, f...</td>\n",
       "      <td>Stack Overflow;How-to videos;Interactive tutorial</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Too long</td>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>I am a developer by profession</td>\n",
       "      <td>18-24 years old</td>\n",
       "      <td>Student, full-time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Secondary school (e.g. American high school, G...</td>\n",
       "      <td>Other online resources (e.g., videos, blogs, f...</td>\n",
       "      <td>Technical documentation;Blogs;Written Tutorial...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Too short</td>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ResponseId                      MainBranch                 Age  \\\n",
       "0           1  I am a developer by profession  Under 18 years old   \n",
       "1           2  I am a developer by profession     35-44 years old   \n",
       "2           3  I am a developer by profession     45-54 years old   \n",
       "3           4           I am learning to code     18-24 years old   \n",
       "4           5  I am a developer by profession     18-24 years old   \n",
       "\n",
       "            Employment RemoteWork   Check  \\\n",
       "0  Employed, full-time     Remote  Apples   \n",
       "1  Employed, full-time     Remote  Apples   \n",
       "2  Employed, full-time     Remote  Apples   \n",
       "3   Student, full-time        NaN  Apples   \n",
       "4   Student, full-time        NaN  Apples   \n",
       "\n",
       "                                    CodingActivities  \\\n",
       "0                                              Hobby   \n",
       "1  Hobby;Contribute to open-source projects;Other...   \n",
       "2  Hobby;Contribute to open-source projects;Other...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             EdLevel  \\\n",
       "0                          Primary/elementary school   \n",
       "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
       "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
       "3  Some college/university study without earning ...   \n",
       "4  Secondary school (e.g. American high school, G...   \n",
       "\n",
       "                                           LearnCode  \\\n",
       "0                             Books / Physical media   \n",
       "1  Books / Physical media;Colleague;On the job tr...   \n",
       "2  Books / Physical media;Colleague;On the job tr...   \n",
       "3  Other online resources (e.g., videos, blogs, f...   \n",
       "4  Other online resources (e.g., videos, blogs, f...   \n",
       "\n",
       "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
       "0                                                NaN  ...            NaN   \n",
       "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
       "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
       "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
       "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
       "\n",
       "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
       "0            NaN            NaN            NaN             NaN   \n",
       "1            0.0            0.0            0.0             0.0   \n",
       "2            NaN            NaN            NaN             NaN   \n",
       "3            NaN            NaN            NaN             NaN   \n",
       "4            NaN            NaN            NaN             NaN   \n",
       "\n",
       "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
       "0             NaN                    NaN        NaN                 NaN    NaN  \n",
       "1             0.0                    NaN        NaN                 NaN    NaN  \n",
       "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
       "3             NaN               Too long       Easy                 NaN    NaN  \n",
       "4             NaN              Too short       Easy                 NaN    NaN  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8102e4ac",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "This step involves cleaning and preparing the dataset to make it ready for our analysis. We will perform the following tasks:\n",
    "\n",
    "1. Identify and remove duplicate rows.\n",
    "2. Drop unecessary columns\n",
    "3. Standardize our data\n",
    "4. Analyze missing values\n",
    "5. Normalize data for comparative analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c035fba",
   "metadata": {},
   "source": [
    "## Identify and remove duplicate rows\n",
    "\n",
    "First, let's identify how many duplicates we have in our dataset.\n",
    "\n",
    "We'll be narrowing our search to the ResponseId, as this is the primary attribute that can help us identify duplicates, since there should only be one id per survey response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "c3f452f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 20\n"
     ]
    }
   ],
   "source": [
    "# Let's identify how many duplicates we have in our dataset\n",
    "dupe_count = df['ResponseId'].duplicated().sum()\n",
    "print(f\"Number of duplicates: {dupe_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5669fde",
   "metadata": {},
   "source": [
    "This tells us there are 20 duplicates in our dataset. Now we want to remove our duplicates from our dataset. We're keeping the first instance and dropping any others that appear in our dataset by setting `keep` to `first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "7f10197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['ResponseId'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44937f0b",
   "metadata": {},
   "source": [
    "We can count our duplicates again to be sure they've been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "92579040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "dupe_count = df['ResponseId'].duplicated().sum()\n",
    "print(f\"Number of duplicates: {dupe_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2141d0",
   "metadata": {},
   "source": [
    "And sure enough, we see there are no duplicates!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b97f12",
   "metadata": {},
   "source": [
    "## Drop unecessary columns\n",
    "\n",
    "Before we move any further, it's a good idea to properly go through each attribute and determine whether we want to keep it for analytical reasons, or drop it to simplify our dataset.\n",
    "\n",
    "Looking at our survey questions from earlier, there are a few that stand out as being unecessary for our purposes:\n",
    "\n",
    "### MainBranch\n",
    "This attribute has the following response options:\n",
    "- I am a developer by profession\n",
    "- I am learning to code\n",
    "- I code primarily as a hobby\n",
    "- I am not primarily a developer, but I write code sometimes...\n",
    "- I used to be a developer by profession, but I no long am\n",
    "\n",
    "The information provided by this attribute can be gleamed by others, such as `Employment`, `EdLevel`, and `YearsCode` to name a few.\n",
    "\n",
    "Here are a few other attributes we'll be dropping as they're not useful to our analysis:\n",
    "- Check\n",
    "- CodingActivities\n",
    "- LearnCode\n",
    "- LearnCodeOnline\n",
    "- TechDoc\n",
    "- TechEndorse\n",
    "- MiscTechHaveWorkedWith\n",
    "- MiscTechWantToWorkWith\n",
    "- MiscTechAdmired\n",
    "- SOVisitFreq\n",
    "- SOPartFreq\n",
    "- AISelect\n",
    "- AIBen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645bbbed",
   "metadata": {},
   "source": [
    "To drop columns, we use the `.drop()` method on our dataframe and we set `axis=1` to specify we're droping columns. `axis=0` is for dropping rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "3306e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['MainBranch', 'Check', 'CodingActivities', 'LearnCode', 'LearnCodeOnline', \n",
    "                'TechDoc', 'TechEndorse', 'MiscTechHaveWorkedWith', 'MiscTechWantToWorkWith', \n",
    "                'MiscTechAdmired', 'SOVisitFreq', 'SOPartFreq', 'AISelect', 'AIBen']\n",
    "df.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf2652",
   "metadata": {},
   "source": [
    "We can also see here that there are a multitude of unknown columns not mentioned. We should drop most of these since we don't have any information about what they represent. Some can be inferred and are useful, such as `ConvertedCompYearly`, which seems to represent common compensation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "80de3c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ResponseId', 'Age', 'Employment', 'RemoteWork', 'EdLevel', 'YearsCode',\n",
       "       'YearsCodePro', 'DevType', 'OrgSize', 'PurchaseInfluence', 'BuyNewTool',\n",
       "       'BuildvsBuy', 'Country', 'Currency', 'CompTotal',\n",
       "       'LanguageHaveWorkedWith', 'LanguageWantToWorkWith', 'LanguageAdmired',\n",
       "       'DatabaseHaveWorkedWith', 'DatabaseWantToWorkWith', 'DatabaseAdmired',\n",
       "       'PlatformHaveWorkedWith', 'PlatformWantToWorkWith', 'PlatformAdmired',\n",
       "       'WebframeHaveWorkedWith', 'WebframeWantToWorkWith', 'WebframeAdmired',\n",
       "       'EmbeddedHaveWorkedWith', 'EmbeddedWantToWorkWith', 'EmbeddedAdmired',\n",
       "       'ToolsTechHaveWorkedWith', 'ToolsTechWantToWorkWith',\n",
       "       'ToolsTechAdmired', 'NEWCollabToolsHaveWorkedWith',\n",
       "       'NEWCollabToolsWantToWorkWith', 'NEWCollabToolsAdmired',\n",
       "       'OpSysPersonal use', 'OpSysProfessional use',\n",
       "       'OfficeStackAsyncHaveWorkedWith', 'OfficeStackAsyncWantToWorkWith',\n",
       "       'OfficeStackAsyncAdmired', 'OfficeStackSyncHaveWorkedWith',\n",
       "       'OfficeStackSyncWantToWorkWith', 'OfficeStackSyncAdmired',\n",
       "       'AISearchDevHaveWorkedWith', 'AISearchDevWantToWorkWith',\n",
       "       'AISearchDevAdmired', 'NEWSOSites', 'SOAccount', 'SOHow', 'SOComm',\n",
       "       'AISent', 'AIAcc', 'AIComplex', 'AIToolCurrently Using',\n",
       "       'AIToolInterested in Using', 'AIToolNot interested in Using',\n",
       "       'AINextMuch more integrated', 'AINextNo change',\n",
       "       'AINextMore integrated', 'AINextLess integrated',\n",
       "       'AINextMuch less integrated', 'AIThreat', 'AIEthics', 'AIChallenges',\n",
       "       'TBranch', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2',\n",
       "       'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6',\n",
       "       'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'Frequency_1',\n",
       "       'Frequency_2', 'Frequency_3', 'TimeSearching', 'TimeAnswering',\n",
       "       'Frustration', 'ProfessionalTech', 'ProfessionalCloud',\n",
       "       'ProfessionalQuestion', 'Industry', 'JobSatPoints_1', 'JobSatPoints_4',\n",
       "       'JobSatPoints_5', 'JobSatPoints_6', 'JobSatPoints_7', 'JobSatPoints_8',\n",
       "       'JobSatPoints_9', 'JobSatPoints_10', 'JobSatPoints_11', 'SurveyLength',\n",
       "       'SurveyEase', 'ConvertedCompYearly', 'JobSat'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "cf7f0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ToolsTechHaveWorkedWith -> SurveyEase\n",
    "additional_drop_cols = df.loc[:, \"ToolsTechHaveWorkedWith\":'SurveyEase'].columns\n",
    "df.drop(additional_drop_cols, axis=1, inplace=True)\n",
    "df.drop(['YearsCodePro', 'BuyNewTool', 'Currency', 'CompTotal'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "13fd80f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ResponseId', 'Age', 'Employment', 'RemoteWork', 'EdLevel', 'YearsCode',\n",
       "       'DevType', 'OrgSize', 'PurchaseInfluence', 'BuildvsBuy', 'Country',\n",
       "       'LanguageHaveWorkedWith', 'LanguageWantToWorkWith', 'LanguageAdmired',\n",
       "       'DatabaseHaveWorkedWith', 'DatabaseWantToWorkWith', 'DatabaseAdmired',\n",
       "       'PlatformHaveWorkedWith', 'PlatformWantToWorkWith', 'PlatformAdmired',\n",
       "       'WebframeHaveWorkedWith', 'WebframeWantToWorkWith', 'WebframeAdmired',\n",
       "       'EmbeddedHaveWorkedWith', 'EmbeddedWantToWorkWith', 'EmbeddedAdmired',\n",
       "       'ConvertedCompYearly', 'JobSat'],\n",
       "      dtype='str')"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8fcc67",
   "metadata": {},
   "source": [
    "Now we have a more manageable set of attributes to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8b6bf",
   "metadata": {},
   "source": [
    "## Standardize our Data\n",
    "\n",
    "Before we go and handle for missing values, we want to go through our categorical attributes and standardize where necessary. First, we need to identify which columns are categorical.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "13adec3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Employment',\n",
       " 'RemoteWork',\n",
       " 'EdLevel',\n",
       " 'YearsCode',\n",
       " 'DevType',\n",
       " 'OrgSize',\n",
       " 'PurchaseInfluence',\n",
       " 'BuildvsBuy',\n",
       " 'Country',\n",
       " 'LanguageHaveWorkedWith',\n",
       " 'LanguageWantToWorkWith',\n",
       " 'LanguageAdmired',\n",
       " 'DatabaseHaveWorkedWith',\n",
       " 'DatabaseWantToWorkWith',\n",
       " 'DatabaseAdmired',\n",
       " 'PlatformHaveWorkedWith',\n",
       " 'PlatformWantToWorkWith',\n",
       " 'PlatformAdmired',\n",
       " 'WebframeHaveWorkedWith',\n",
       " 'WebframeWantToWorkWith',\n",
       " 'WebframeAdmired',\n",
       " 'EmbeddedHaveWorkedWith',\n",
       " 'EmbeddedWantToWorkWith',\n",
       " 'EmbeddedAdmired']"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# str data types are categorical\n",
    "categorical = [var for var in df.columns if df[var].dtype=='str']\n",
    "categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1b02fd",
   "metadata": {},
   "source": [
    "Next we want to go through each one and identify the unique values. For many, no changes will be necessary, but for some we'll want to standardize the values to either be easier to read or even condense some categories into a single one. For the purpose of this notebook I will only show the attributes that needed standardizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7879f2d",
   "metadata": {},
   "source": [
    "### Employment\n",
    "\n",
    "The employment attribute has 110 unique entires. However this is deceiving, the respondents were allowed to select multiple options. This means there are fewer Employment categories than what is being returned by the `unique.()` method. We need to break this down further by string splitting our results and returning unique options again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "96314b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employed, full-time\n",
      "Student, full-time\n",
      "Student, full-time;Not employed, but looking for work\n",
      "Independent contractor, freelancer, or self-employed\n",
      "Not employed, and not looking for work\n",
      "Employed, full-time;Student, part-time\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed\n",
      "Employed, full-time;Student, full-time\n",
      "Employed, part-time\n",
      "Student, full-time;Employed, part-time\n",
      "Student, part-time;Employed, part-time\n",
      "I prefer not to say\n",
      "Not employed, but looking for work\n",
      "Student, part-time\n",
      "Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed;Student, part-time\n",
      "Independent contractor, freelancer, or self-employed;Employed, part-time\n",
      "Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time\n",
      "Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed\n",
      "Student, full-time;Independent contractor, freelancer, or self-employed\n",
      "Employed, full-time;Employed, part-time\n",
      "Not employed, but looking for work;Independent contractor, freelancer, or self-employed\n",
      "Student, full-time;Not employed, and not looking for work\n",
      "Retired\n",
      "Independent contractor, freelancer, or self-employed;Student, part-time\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time\n",
      "Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time\n",
      "Not employed, but looking for work;Student, part-time\n",
      "Not employed, but looking for work;Not employed, and not looking for work\n",
      "Independent contractor, freelancer, or self-employed;Retired\n",
      "Not employed, but looking for work;Student, part-time;Employed, part-time\n",
      "Student, full-time;Not employed, but looking for work;Not employed, and not looking for work\n",
      "Employed, full-time;Not employed, but looking for work\n",
      "Student, full-time;Not employed, and not looking for work;Student, part-time\n",
      "Employed, full-time;Retired\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time\n",
      "Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work\n",
      "Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Employed, part-time\n",
      "Not employed, but looking for work;Employed, part-time\n",
      "Employed, full-time;Student, full-time;Employed, part-time\n",
      "Independent contractor, freelancer, or self-employed;Not employed, and not looking for work\n",
      "Not employed, and not looking for work;Student, part-time\n",
      "Student, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time\n",
      "Student, full-time;Student, part-time\n",
      "Student, full-time;Not employed, but looking for work;Student, part-time\n",
      "Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Retired\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work\n",
      "Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed\n",
      "Employed, full-time;Student, full-time;Student, part-time\n",
      "Not employed, but looking for work;Retired\n",
      "Employed, full-time;Student, full-time;Not employed, but looking for work\n",
      "Not employed, and not looking for work;Retired\n",
      "Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Retired\n",
      "Employed, full-time;Not employed, but looking for work;Employed, part-time\n",
      "Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time;Retired\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time\n",
      "Student, full-time;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work\n",
      "Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time;Employed, part-time;Retired\n",
      "Employed, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed\n",
      "Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time\n",
      "Student, full-time;Not employed, but looking for work;Retired\n",
      "Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time\n",
      "Student, part-time;Retired\n",
      "Student, full-time;Not employed, but looking for work;Not employed, and not looking for work;Student, part-time\n",
      "Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time\n",
      "Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Retired\n",
      "Employed, full-time;Student, full-time;Student, part-time;Employed, part-time\n",
      "Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time\n",
      "Student, full-time;Not employed, but looking for work;Employed, part-time\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time\n",
      "Independent contractor, freelancer, or self-employed;Student, part-time;Retired\n",
      "Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Retired\n",
      "Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work\n",
      "Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Employed, part-time\n",
      "Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time\n",
      "Independent contractor, freelancer, or self-employed;Employed, part-time;Retired\n",
      "Employed, full-time;Not employed, and not looking for work\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed;Retired\n",
      "Student, full-time;Student, part-time;Employed, part-time\n",
      "Employed, part-time;Retired\n",
      "Employed, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time;Retired\n",
      "Employed, full-time;Student, part-time;Employed, part-time\n",
      "Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time;Retired\n",
      "Student, full-time;Student, part-time;Retired\n",
      "Student, full-time;Not employed, and not looking for work;Employed, part-time\n",
      "Employed, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Employed, part-time\n",
      "Not employed, but looking for work;Not employed, and not looking for work;Student, part-time;Employed, part-time\n",
      "Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time\n",
      "Employed, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time\n",
      "Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time;Employed, part-time\n",
      "Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time\n",
      "Not employed, and not looking for work;Employed, part-time\n",
      "Employed, full-time;Student, full-time;Not employed, but looking for work;Student, part-time\n",
      "Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Employed, part-time\n",
      "Employed, full-time;Not employed, but looking for work;Not employed, and not looking for work;Employed, part-time\n",
      "Student, full-time;Independent contractor, freelancer, or self-employed;Employed, part-time;Retired\n",
      "Not employed, but looking for work;Student, part-time;Retired\n",
      "Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time;Retired\n",
      "Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed\n",
      "Not employed, but looking for work;Not employed, and not looking for work;Student, part-time\n",
      "Employed, full-time;Student, full-time;Independent contractor, freelancer, or self-employed;Student, part-time;Retired\n",
      "Employed, full-time;Student, full-time;Not employed, but looking for work;Student, part-time;Employed, part-time\n",
      "Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Student, part-time\n",
      "Employed, full-time;Student, full-time;Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Employed, part-time;Retired\n",
      "Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Not employed, and not looking for work;Employed, part-time\n",
      "Student, full-time;Retired\n",
      "Employed, full-time;Not employed, but looking for work;Student, part-time\n",
      "Not employed, and not looking for work;Student, part-time;Employed, part-time\n",
      "Not employed, but looking for work;Independent contractor, freelancer, or self-employed;Student, part-time;Retired\n"
     ]
    }
   ],
   "source": [
    "for type in df['Employment'].unique():\n",
    "    print(type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8b4402",
   "metadata": {},
   "source": [
    "Now that we've broken down our employment types further, we see that we can simplify them. There are multiple types of employment listed, but we only really care about these for our purposes:\n",
    "- Employed\n",
    "- Student\n",
    "- Not employed\n",
    "- Independent contractor\n",
    "- I prefer not to say\n",
    "- Retired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "c1a79247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                                 'Employed, full-time',\n",
       "                                   'Student, full-time',\n",
       "                   'Not employed, but looking for work',\n",
       " 'Independent contractor, freelancer, or self-employed',\n",
       "               'Not employed, and not looking for work',\n",
       "                                   'Student, part-time',\n",
       "                                  'Employed, part-time',\n",
       "                                  'I prefer not to say',\n",
       "                                              'Retired']\n",
       "Length: 9, dtype: str"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Employment_categories = df['Employment'].str.split(';').explode('Employment').unique()\n",
    "Employment_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20f71a",
   "metadata": {},
   "source": [
    "At first glance this seems simple. We can strip everything after the comma in the response. However, it's more complicated than that. The respondents were allowed to select multiple options. This means that we need a way to prioritize some responses over another.\n",
    "\n",
    "Here is the order of priority I have selected:\n",
    "1. Retired\n",
    "2. Student\n",
    "3. Employed\n",
    "4. Independent contractor\n",
    "5. Not employed\n",
    "6. I prefer not to say\n",
    "\n",
    "For each entry we need to do the following:\n",
    "- Split each employment type using the semicolon\n",
    "- Only pull the value before the comma\n",
    "- Select an entry based on order of priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "bb82362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_employment(response: str) -> str | None:\n",
    "    if pd.isna(response): return None\n",
    "\n",
    "    PRIORITY = ['Retired', 'Student', 'Employed', 'Independent contractor', 'Not employed', 'I prefer not to say']\n",
    "\n",
    "    selections = set()\n",
    "\n",
    "    # simplify entry\n",
    "    for selection in response.split(';'):\n",
    "        base_value = selection.split(',')[0]\n",
    "        selections.add(base_value)\n",
    "\n",
    "    for category in PRIORITY:\n",
    "        if category in selections:\n",
    "            return category.title()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "0ae4c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employment'] = df['Employment'].apply(simplify_employment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "a6e78b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[              'Employed',                'Student', 'Independent Contractor',\n",
       "           'Not Employed',    'I Prefer Not To Say',                'Retired']\n",
       "Length: 6, dtype: str"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Employment'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877c2895",
   "metadata": {},
   "source": [
    "And just like that, we've simplified our Employment category!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c036a",
   "metadata": {},
   "source": [
    "## RemoteWork\n",
    "\n",
    "For this attribute, we just want simplify the `Hybrid (some remote, some in-person)` entry to `Hybrid` for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "e01700d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "['Remote', nan, 'In-person', 'Hybrid (some remote, some in-person)']\n",
       "Length: 4, dtype: str"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RemoteWork'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "3e7d5b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RemoteWork'] = df['RemoteWork'].replace('Hybrid (some remote, some in-person)', 'Hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d6382c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "['Remote', nan, 'In-person', 'Hybrid']\n",
       "Length: 4, dtype: str"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['RemoteWork'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac793891",
   "metadata": {},
   "source": [
    "## EdLevel\n",
    "For this attribute, we want to simplify the entries for readability, similar to what we did for `Hybrid` with RemoteWork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "4cf2b32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                                                         'Primary/elementary school',\n",
       "                                       'Bachelor’s degree (B.A., B.S., B.Eng., etc.)',\n",
       "                                    'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)',\n",
       "                             'Some college/university study without earning a degree',\n",
       " 'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)',\n",
       "                                     'Professional degree (JD, MD, Ph.D, Ed.D, etc.)',\n",
       "                                                'Associate degree (A.A., A.S., etc.)',\n",
       "                                                                     'Something else',\n",
       "                                                                                  nan]\n",
       "Length: 9, dtype: str"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EdLevel'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "b0a920b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "edu_map = {\n",
    "    'Primary/elementary school': 'Elementary',\n",
    "    'Bachelor’s degree (B.A., B.S., B.Eng., etc.)': 'Bachelor\\'s',\n",
    "    'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)': 'Master\\'s',\n",
    "    'Some college/university study without earning a degree': 'Some post-secondary',\n",
    "    'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)': 'Secondary',\n",
    "    'Professional degree (JD, MD, Ph.D, Ed.D, etc.)': 'Professional degree',\n",
    "    'Associate degree (A.A., A.S., etc.)': 'Associate degree'\n",
    "}\n",
    "df['EdLevel'] = df['EdLevel'].map(edu_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "5d233c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[         'Elementary',          'Bachelor's',            'Master's',\n",
       " 'Some post-secondary',           'Secondary', 'Professional degree',\n",
       "    'Associate degree',                   nan]\n",
       "Length: 8, dtype: str"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EdLevel'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011d7d2",
   "metadata": {},
   "source": [
    "## YearsCode\n",
    "For this attribute, we actually want to convert it to integer values, since all but two of these values are the actual number of years. First, we need to convert `Less than 1 year` and `More than 50 years` to a number value. We'll assign `1` to the former and `50` to the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "8c6174af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                 nan,                 '20',                 '37',\n",
       "                  '4',                  '9',                 '10',\n",
       "                  '7',                  '1',                 '15',\n",
       "                 '30',                 '31',                  '6',\n",
       "                 '12',                 '22',                  '5',\n",
       "                 '36',                 '25',                 '44',\n",
       "                 '24',                 '18',                  '3',\n",
       "                  '8', 'More than 50 years',                 '11',\n",
       "                 '29',                 '40',                 '39',\n",
       "                  '2',                 '42',                 '34',\n",
       "                 '19',                 '35',                 '16',\n",
       "                 '33',                 '13',                 '23',\n",
       "                 '14',                 '28',                 '17',\n",
       "                 '21',                 '43',                 '46',\n",
       "                 '26',                 '32',                 '41',\n",
       "                 '45',                 '27',                 '38',\n",
       "                 '50',                 '48',                 '47',\n",
       "   'Less than 1 year',                 '49']\n",
       "Length: 53, dtype: str"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['YearsCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "7ba57dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearsCode'] = df['YearsCode'].replace('More than 50 years', '50')\n",
    "df['YearsCode'] = df['YearsCode'].replace('Less than 1 year', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "99b77e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[ nan, '20', '37',  '4',  '9', '10',  '7',  '1', '15', '30', '31',  '6', '12',\n",
       " '22',  '5', '36', '25', '44', '24', '18',  '3',  '8', '50', '11', '29', '40',\n",
       " '39',  '2', '42', '34', '19', '35', '16', '33', '13', '23', '14', '28', '17',\n",
       " '21', '43', '46', '26', '32', '41', '45', '27', '38', '48', '47', '49']\n",
       "Length: 51, dtype: str"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['YearsCode'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd886b19",
   "metadata": {},
   "source": [
    "Now that all values except nan are numbers, we want to actually convert the years into float values. Because we still have NaN values, we need to use `to_numeric()` with `coerce` error handling.\n",
    "\n",
    "Why float instead of integer? Because later when we replace na values, we want to be able to use the mean, which will return a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "5a7f3cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearsCode'] = pd.to_numeric(df['YearsCode'], errors='coerce').astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd2763",
   "metadata": {},
   "source": [
    "We'll handle the `NaN` values in the next section, as we've now converted this column to a numerical category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdacc563",
   "metadata": {},
   "source": [
    "## DevType\n",
    "This column has too many categories and needs to be streamlined somehow. Many of these categories should be folded into one to reduce the number to a manageable one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "1b32adf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                                            nan,\n",
       "                         'Developer, full-stack',\n",
       "                          'Developer Experience',\n",
       "                                       'Student',\n",
       "                           'Academic researcher',\n",
       "                               'Project manager',\n",
       "                            'Developer Advocate',\n",
       "                           'Developer, back-end',\n",
       "                       'Other (please specify):',\n",
       "                          'Developer, front-end',\n",
       "                        'Database administrator',\n",
       " 'Developer, desktop or enterprise applications',\n",
       "                 'Cloud infrastructure engineer',\n",
       " 'Data scientist or machine learning specialist',\n",
       "                   'Research & Development role',\n",
       "   'Developer, embedded applications or devices',\n",
       "                          'System administrator',\n",
       "                             'DevOps specialist',\n",
       "                           'Engineering manager',\n",
       "                                      'Designer',\n",
       "                         'Security professional',\n",
       "          'Senior Executive (C-Suite, VP, etc.)',\n",
       "                             'Developer, mobile',\n",
       "                   'Developer, game or graphics',\n",
       "                      'Data or business analyst',\n",
       "                                      'Educator',\n",
       "                         'Developer, QA or test',\n",
       "                               'Product manager',\n",
       "                                 'Developer, AI',\n",
       "                                     'Scientist',\n",
       "                    'Engineer, site reliability',\n",
       "                                    'Blockchain',\n",
       "               'Marketing or sales professional',\n",
       "                             'Hardware Engineer',\n",
       "                                 'Data engineer']\n",
       "Length: 35, dtype: str"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DevType'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0215b0",
   "metadata": {},
   "source": [
    "Having scrolled through, I believe we can condense these categories into the following:\n",
    "- Developer\n",
    "- Student\n",
    "- Researcher\n",
    "- Manager\n",
    "- Database administrator\n",
    "- Engineer\n",
    "- Data scientist\n",
    "- System administrator\n",
    "- DevOps\n",
    "- Designer\n",
    "- Security professional\n",
    "- Data analyst\n",
    "- Educator\n",
    "- Scientist\n",
    "- Blockchain\n",
    "- Marketing\n",
    "\n",
    "All the Developer types have been folded into a single type. Likewise Engineers were combined into a single type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "3503cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "devType_map = {\n",
    "    'Developer, full-stack': 'Developer',\n",
    "    'Developer Experience': 'Developer',\n",
    "    'Student': 'Student',\n",
    "    'Academic researcher': 'Researcher',\n",
    "    'Project manager': 'Manager',\n",
    "    'Developer Advocate': 'Developer',\n",
    "    'Developer, back-end': 'Developer',\n",
    "    'Other (please specify)': np.nan,\n",
    "    'Developer, front-end': 'Developer',\n",
    "    'Database administrator': 'Database administrator',\n",
    "    'Developer, desktop or enterprise applications': 'Developer',\n",
    "    'Cloud infrastructure engineer': 'Engineer',\n",
    "    'Data scientist or machine learning specialist': 'Data scientist',\n",
    "    'Research & Development role': 'Researcher',\n",
    "    'Developer, embedded applications or devices': 'Developer',\n",
    "    'DevOps specialist': 'DevOps',\n",
    "    'Engineer manager': 'Manager',\n",
    "    'Designer': 'Designer',\n",
    "    'Security professional': 'Security professional',\n",
    "    'Senior Executive (C-Suite, VP, etc.)': 'Executive',\n",
    "    'Developer, mobile': 'Developer',\n",
    "    'Developer, game or graphics': 'Developer',\n",
    "    'Data or business analyst': 'Data analyst',\n",
    "    'Educator': 'Educator',\n",
    "    'Developer, QA or test': 'Developer',\n",
    "    'Product manager': 'Manager',\n",
    "    'Developer, AI': 'Developer',\n",
    "    'Scientist': 'Scientist',\n",
    "    'Engineer, site reliability': 'Engineer',\n",
    "    'Blockchain': 'Blockchain',\n",
    "    'Marketing or sales professional': 'Marketing',\n",
    "    'Hardware Engineer': 'Engineer',\n",
    "    'Data engineer': 'Engineer'\n",
    "}\n",
    "\n",
    "df['DevType'] = df['DevType'].map(devType_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "315e9403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                     nan,              'Developer',                'Student',\n",
       "             'Researcher',                'Manager', 'Database administrator',\n",
       "               'Engineer',         'Data scientist',                 'DevOps',\n",
       "               'Designer',  'Security professional',              'Executive',\n",
       "           'Data analyst',               'Educator',              'Scientist',\n",
       "             'Blockchain',              'Marketing']\n",
       "Length: 17, dtype: str"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DevType'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61fcb2",
   "metadata": {},
   "source": [
    "## BuildvsBuy\n",
    "For this section, we juts need to rename each category to be easier to read in visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "0fd65c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                                                                          nan,\n",
       "      'Is ready-to-go but also customizable for growth and targeted use cases',\n",
       " 'Is set up to be customized and needs to be engineered into a usable product',\n",
       "            'Out-of-the-box is ready to go with little need for customization']\n",
       "Length: 4, dtype: str"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BuildvsBuy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "a0848df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BvB_map = {\n",
    "    'Is ready-to-go but also customizable for growth and targeted use cases': 'Ready-to-go and customizable',\n",
    "    'Is set up to be customized and needs to be engineered into a usable product': 'Customizable',\n",
    "    'Out-of-the-box is ready to go with little need for customization': 'Ready-to-go'\n",
    "}\n",
    "df['BuildvsBuy'] = df['BuildvsBuy'].map(BvB_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "870f8e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[nan, 'Ready-to-go and customizable', 'Customizable', 'Ready-to-go']\n",
       "Length: 4, dtype: str"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['BuildvsBuy'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14b5d75",
   "metadata": {},
   "source": [
    "## Country\n",
    "There are many countries listed in this column. Some of them have long names and need to be reduced or abbreviated. There are also a lot of inconsistent names, like Republic of Korea for South Korea, and so on. These all need to be updated to ensure consistent naming across countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "b94c32a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States of America\n",
      "United Kingdom of Great Britain and Northern Ireland\n",
      "Canada\n",
      "Norway\n",
      "Uzbekistan\n",
      "Serbia\n",
      "Poland\n",
      "Philippines\n",
      "Bulgaria\n",
      "Switzerland\n",
      "India\n",
      "Germany\n",
      "Ireland\n",
      "Italy\n",
      "Ukraine\n",
      "Australia\n",
      "Brazil\n",
      "Japan\n",
      "Austria\n",
      "Iran, Islamic Republic of...\n",
      "France\n",
      "Saudi Arabia\n",
      "Romania\n",
      "Turkey\n",
      "Nepal\n",
      "Algeria\n",
      "Sweden\n",
      "Netherlands\n",
      "Croatia\n",
      "Pakistan\n",
      "Czech Republic\n",
      "Republic of North Macedonia\n",
      "Finland\n",
      "Slovakia\n",
      "Russian Federation\n",
      "Greece\n",
      "Israel\n",
      "Belgium\n",
      "Mexico\n",
      "United Republic of Tanzania\n",
      "Hungary\n",
      "Argentina\n",
      "Portugal\n",
      "Sri Lanka\n",
      "Latvia\n",
      "China\n",
      "Singapore\n",
      "Lebanon\n",
      "Spain\n",
      "South Africa\n",
      "Lithuania\n",
      "Viet Nam\n",
      "Dominican Republic\n",
      "Indonesia\n",
      "Kosovo\n",
      "Morocco\n",
      "Taiwan\n",
      "Georgia\n",
      "San Marino\n",
      "Tunisia\n",
      "Bangladesh\n",
      "Nigeria\n",
      "Liechtenstein\n",
      "Denmark\n",
      "Ecuador\n",
      "Malaysia\n",
      "Albania\n",
      "Azerbaijan\n",
      "Chile\n",
      "Ghana\n",
      "Peru\n",
      "Bolivia\n",
      "Egypt\n",
      "Luxembourg\n",
      "Montenegro\n",
      "Cyprus\n",
      "Paraguay\n",
      "Kazakhstan\n",
      "Slovenia\n",
      "Jordan\n",
      "Venezuela, Bolivarian Republic of...\n",
      "Costa Rica\n",
      "Jamaica\n",
      "Thailand\n",
      "Nicaragua\n",
      "Myanmar\n",
      "Republic of Korea\n",
      "Rwanda\n",
      "Bosnia and Herzegovina\n",
      "Benin\n",
      "El Salvador\n",
      "Zimbabwe\n",
      "Afghanistan\n",
      "Estonia\n",
      "Malta\n",
      "Uruguay\n",
      "Belarus\n",
      "Colombia\n",
      "Republic of Moldova\n",
      "Isle of Man\n",
      "Nomadic\n",
      "New Zealand\n",
      "Palestine\n",
      "Armenia\n",
      "United Arab Emirates\n",
      "Maldives\n",
      "Ethiopia\n",
      "Fiji\n",
      "Guatemala\n",
      "Uganda\n",
      "Turkmenistan\n",
      "Mauritius\n",
      "Kenya\n",
      "Cuba\n",
      "Gabon\n",
      "Bahamas\n",
      "South Korea\n",
      "Iceland\n",
      "Honduras\n",
      "Hong Kong (S.A.R.)\n",
      "Lao People's Democratic Republic\n",
      "Mongolia\n",
      "Cambodia\n",
      "Madagascar\n",
      "Angola\n",
      "Democratic Republic of the Congo\n",
      "Syrian Arab Republic\n",
      "Iraq\n",
      "Namibia\n",
      "Senegal\n",
      "Kyrgyzstan\n",
      "Zambia\n",
      "Swaziland\n",
      "Côte d'Ivoire\n",
      "Kuwait\n",
      "Tajikistan\n",
      "Burundi\n",
      "Trinidad and Tobago\n",
      "Mauritania\n",
      "Sierra Leone\n",
      "Panama\n",
      "Somalia\n",
      "North Korea\n",
      "Dominica\n",
      "Guyana\n",
      "Togo\n",
      "Oman\n",
      "Barbados\n",
      "Andorra\n",
      "Democratic People's Republic of Korea\n",
      "Qatar\n",
      "Sudan\n",
      "Cameroon\n",
      "Papua New Guinea\n",
      "Bahrain\n",
      "Yemen\n",
      "Malawi\n",
      "Burkina Faso\n",
      "Congo, Republic of the...\n",
      "Botswana\n",
      "Guinea-Bissau\n",
      "Mozambique\n",
      "Central African Republic\n",
      "Equatorial Guinea\n",
      "Suriname\n",
      "Belize\n",
      "Libyan Arab Jamahiriya\n",
      "Cape Verde\n",
      "Brunei Darussalam\n",
      "Bhutan\n",
      "Guinea\n",
      "Niger\n",
      "Antigua and Barbuda\n",
      "Mali\n",
      "Samoa\n",
      "Lesotho\n",
      "Saint Kitts and Nevis\n",
      "Monaco\n",
      "Micronesia, Federated States of...\n",
      "Haiti\n",
      "nan\n",
      "Nauru\n",
      "Liberia\n",
      "Chad\n",
      "Djibouti\n",
      "Solomon Islands\n"
     ]
    }
   ],
   "source": [
    "for country in df['Country'].unique():\n",
    "    print(country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "54e01081",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_rename_arr = [\n",
    "    ['United States of America', 'US'],\n",
    "    ['United Kingdom of Great Britain and Northern Ireland', 'UK'],\n",
    "    ['Iran, Islamic Republic of...', 'Iran'],\n",
    "    ['Republic of North Macedonia', 'North Macedonia'],\n",
    "    ['Russian Federation', 'Russia'],\n",
    "    ['United Republic of Tanzania', 'Tanzania'],\n",
    "    ['Viet Nam', 'Vietnam'],\n",
    "    ['Venezuela, Bolivarian Republic of...', 'Venezuela'],\n",
    "    ['Republic of Korea', 'South Korea'],\n",
    "    ['Republic of Moldova', 'Moldova'],\n",
    "    ['Hong Kong (S.A.R.)', 'Hong Kong'],\n",
    "    ['Lao People\\'s Democratic Republic', 'Laos'],\n",
    "    ['Democratic Republic of the Congo', 'Congo'],\n",
    "    ['Democratic People\\'s Republic of Korea', 'North Korea'],\n",
    "    ['Congo, Republic of the...', 'Congo'],\n",
    "    ['Micronesia, Federated States of...', 'Micronesia']\n",
    "]\n",
    "\n",
    "for rename in country_rename_arr:\\\n",
    "    df['Country'] = df['Country'].replace(rename[0], rename[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "a5356c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StringArray>\n",
       "[                   'US',                    'UK',                'Canada',\n",
       "                'Norway',            'Uzbekistan',                'Serbia',\n",
       "                'Poland',           'Philippines',              'Bulgaria',\n",
       "           'Switzerland',\n",
       " ...\n",
       " 'Saint Kitts and Nevis',                'Monaco',            'Micronesia',\n",
       "                 'Haiti',                     nan,                 'Nauru',\n",
       "               'Liberia',                  'Chad',              'Djibouti',\n",
       "       'Solomon Islands']\n",
       "Length: 183, dtype: str"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c255ee",
   "metadata": {},
   "source": [
    "## Analyze Missing Values\n",
    "\n",
    "Our next step is to handle missing values. There are a multitude of ways we can do this:\n",
    "- Drop them entirely\n",
    "- Replace them with the average (`mean()`) value (numerical)\n",
    "- Replace them with the most common value (categorical, but can also be done wiht numerical)\n",
    "- Left as-is (depending on how we do our analysis)\n",
    "\n",
    "Before we actually handle the missing values, we need to identify which columns have missing values in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "82adf210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "RemoteWork: 10631\n",
      "EdLevel: 5585\n",
      "YearsCode: 5568\n",
      "DevType: 10277\n",
      "OrgSize: 17957\n",
      "PurchaseInfluence: 18031\n",
      "BuildvsBuy: 22079\n",
      "Country: 6507\n",
      "LanguageHaveWorkedWith: 5692\n",
      "LanguageWantToWorkWith: 9685\n",
      "LanguageAdmired: 14565\n",
      "DatabaseHaveWorkedWith: 15183\n",
      "DatabaseWantToWorkWith: 22879\n",
      "DatabaseAdmired: 26880\n",
      "PlatformHaveWorkedWith: 23071\n",
      "PlatformWantToWorkWith: 30905\n",
      "PlatformAdmired: 31377\n",
      "WebframeHaveWorkedWith: 20276\n",
      "WebframeWantToWorkWith: 26902\n",
      "WebframeAdmired: 30494\n",
      "EmbeddedHaveWorkedWith: 22214\n",
      "EmbeddedWantToWorkWith: 17600\n",
      "EmbeddedAdmired: 16733\n",
      "ConvertedCompYearly: 23435\n",
      "JobSat: 29126\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull()\n",
    "columns_with_na = []\n",
    "print('Missing values:')\n",
    "for column in missing_data.columns.values.tolist():\n",
    "    series_count = missing_data[column].value_counts()\n",
    "    if series_count.size > 1:\n",
    "        count_na = series_count.values[1]\n",
    "        print(f\"{column}: {count_na}\")\n",
    "        columns_with_na.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a94e9c",
   "metadata": {},
   "source": [
    "That's quite a lot of missing values! We'll need to identify each one and determine how to handle them. Like previously, we probably want to identify all numerical columns, as there is a good change we will handle them all the same way, by replacing missing values with the average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6009b59f",
   "metadata": {},
   "source": [
    "### Numerical\n",
    "First, let's identify which columns are numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "f6cb9de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsCode type: float64\n",
      "ConvertedCompYearly type: float64\n",
      "JobSat type: float64\n"
     ]
    }
   ],
   "source": [
    "#identify numerical columns\n",
    "na_cols_numerical = []\n",
    "for column in columns_with_na:\n",
    "    if df[column].dtype != 'str':\n",
    "        print(f'{column} type: {df[column].dtype}')\n",
    "        na_cols_numerical.append(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf3aa91",
   "metadata": {},
   "source": [
    "Luckily, there are only three columns with numerical values. We can replace the na values with the average of the remaining values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "44687cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in na_cols_numerical:\n",
    "    df[column] = df[column].fillna(df[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "115eba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YearsCode\n",
      "False    65437\n",
      "Name: count, dtype: int64\n",
      "ConvertedCompYearly\n",
      "False    65437\n",
      "Name: count, dtype: int64\n",
      "JobSat\n",
      "False    65437\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull()\n",
    "\n",
    "for column in na_cols_numerical:\n",
    "    print(missing_data[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a7839b",
   "metadata": {},
   "source": [
    "Now we've confirmed our missing values for numerical columns are replaced with the average values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2adb3c",
   "metadata": {},
   "source": [
    "### Categorical\n",
    "\n",
    "There are several types of missing data when it comes to categorical data. They fall into three categories:\n",
    "\n",
    "#### Missing Completely At Random\n",
    "The missing data is unrelated to observed or unobserved data, such as random logging failure.\n",
    "\n",
    "#### Missing At Random\n",
    "Missingness depends on other observed variables, such as employment type missing for older survey respondents vs newer ones. \n",
    "\n",
    "#### Missing Not At Random\n",
    "Missingness depends on the values themselves, such as a contractor skipping questions not relevant to them.\n",
    "\n",
    "The type of missing value determines how we handle them. In our case, our missing values are considered `Missing Not At Random`, meaning that the questions weren't answered by the respondents on purposes, not my chance or error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "a12ea37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemoteWork type: str\n",
      "EdLevel type: str\n",
      "DevType type: str\n",
      "OrgSize type: str\n",
      "PurchaseInfluence type: str\n",
      "BuildvsBuy type: str\n",
      "Country type: str\n",
      "LanguageHaveWorkedWith type: str\n",
      "LanguageWantToWorkWith type: str\n",
      "LanguageAdmired type: str\n",
      "DatabaseHaveWorkedWith type: str\n",
      "DatabaseWantToWorkWith type: str\n",
      "DatabaseAdmired type: str\n",
      "PlatformHaveWorkedWith type: str\n",
      "PlatformWantToWorkWith type: str\n",
      "PlatformAdmired type: str\n",
      "WebframeHaveWorkedWith type: str\n",
      "WebframeWantToWorkWith type: str\n",
      "WebframeAdmired type: str\n",
      "EmbeddedHaveWorkedWith type: str\n",
      "EmbeddedWantToWorkWith type: str\n",
      "EmbeddedAdmired type: str\n"
     ]
    }
   ],
   "source": [
    "na_cols_categorical = []\n",
    "for column in columns_with_na:\n",
    "    if df[column].dtype == 'str':\n",
    "        print(f'{column} type: {df[column].dtype}')\n",
    "        na_cols_categorical.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f2c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65437"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "4049ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemoteWork (6.16% missing)\n",
      "EdLevel (11.72% missing)\n",
      "DevType (6.37% missing)\n",
      "OrgSize (3.64% missing)\n",
      "PurchaseInfluence (3.63% missing)\n",
      "BuildvsBuy (2.96% missing)\n",
      "Country (10.06% missing)\n",
      "LanguageHaveWorkedWith (11.5% missing)\n",
      "LanguageWantToWorkWith (6.76% missing)\n",
      "LanguageAdmired (4.49% missing)\n",
      "DatabaseHaveWorkedWith (4.31% missing)\n",
      "DatabaseWantToWorkWith (2.86% missing)\n",
      "DatabaseAdmired (2.43% missing)\n",
      "PlatformHaveWorkedWith (2.84% missing)\n",
      "PlatformWantToWorkWith (2.12% missing)\n",
      "PlatformAdmired (2.09% missing)\n",
      "WebframeHaveWorkedWith (3.23% missing)\n",
      "WebframeWantToWorkWith (2.43% missing)\n",
      "WebframeAdmired (2.15% missing)\n",
      "EmbeddedHaveWorkedWith (2.95% missing)\n",
      "EmbeddedWantToWorkWith (3.72% missing)\n",
      "EmbeddedAdmired (3.91% missing)\n"
     ]
    }
   ],
   "source": [
    "missing_data = df.isnull()\n",
    "\n",
    "for column in na_cols_categorical:\n",
    "    percent_missing = len(df) / missing_data[column].value_counts().values[1]\n",
    "    print(f\"{column} ({round(percent_missing, 2)}% missing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45bd10",
   "metadata": {},
   "source": [
    "In the context of our dataset, missing values indicate an absense of selection, not necessarily actual missing values. Our categorical variables fall into two groups:\n",
    "\n",
    "##### Group A - Single-choice attributes\n",
    "- EdLevel\n",
    "- DevType\n",
    "- OrgSize\n",
    "- PurchaseInfluence\n",
    "- BuildvsBuy\n",
    "- Country\n",
    "\n",
    "For these missing values we'll be replacing NaN with 'Not answered'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "5df76f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_choice_columns = ['EdLevel', 'DevType', 'OrgSize', 'PurchaseInfluence', 'BuildvsBuy', 'Country']\n",
    "\n",
    "for column in single_choice_columns:\n",
    "    df[column] = df[column].fillna('Not answered')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b34d54e",
   "metadata": {},
   "source": [
    "#### Group B - Multi-select attributes\n",
    "- LanguageHaveWorkedWith\n",
    "- LanguageWantWorkWith\n",
    "- etc....\n",
    "\n",
    "We can replace NaN with an empty set, and split the actual responses into lists. Then later we can explode the answers to get a count of technology selection. However this poses an additional challenge. How do we store this information in a csv? The answer is we can't. CSVs do not allow for storing complex information like arrays and lists. This means at this point we should save our data in a 'clean' csv format where we keep the NaN values for these columns, then at load time we can modify them to be treated as empty sets for missign values, and lists of selected technologies for the rest. A better long-term solution would be to normalize the data and store it in a relational database, but for the purpose of this project we'll keep using CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dce7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our cleaned data into a .csv\n",
    "df.to_csv('survey-data-cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278b42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0719e484",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff7415f",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
